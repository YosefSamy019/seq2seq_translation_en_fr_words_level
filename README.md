---

# ğŸŒ Sequence-to-Sequence Translation Model with Attention

This project builds, trains, and serves a **Sequence-to-Sequence (Seq2Seq)** translation model (English â¡ French) using TensorFlow/Keras, attention mechanism, and a Streamlit web app for interactive translation.

---

## ğŸ“Œ Overview

* **Model type:** Seq2Seq with attention (encoder-decoder architecture)
* **Input:** English sentences (max 35 tokens)
* **Output:** French sentences (max 35 tokens)
* **Libraries:** TensorFlow, Keras, Streamlit, Numpy, Pandas, Seaborn
* **Deployment:** Streamlit app for real-time translation

---

## ğŸš€ Workflow

### 1ï¸âƒ£ **Importing Libraries**

Loads essential Python and deep learning libraries for data handling, visualization, and model building.

### 2ï¸âƒ£ **Constants & Config**

Defines model configuration:

* Input/output sequence lengths
* Embedding dimensions
* Context vector length (LSTM units)
* Tokenizer vocab size, special tokens
* Paths for saving models, tokenizers, and outputs

### 3ï¸âƒ£ **Dataset Preparation**

* Loads English-French sentence pairs from `fra.txt`
* Cleans text (removes special characters, lowercases)
* Adds `START_TOKEN` and `END_TOKEN`
* Visualizes sentence length distributions

### 4ï¸âƒ£ **Tokenization**

* Creates and fits tokenizers
* Converts text to integer sequences
* Applies padding

### 5ï¸âƒ£ **Model Architecture**

* **Encoder:** Embedding â†’ BiLSTM â†’ LSTM
* **Decoder:** Embedding â†’ stacked LSTMs with residuals + normalization
* **Attention:** dot-product attention to align input and output sequences
* **Training model:** combines encoder, decoder, and attention

### 6ï¸âƒ£ **Training**

* Compiles with `rmsprop` + `sparse_categorical_crossentropy`
* Trains with checkpointing and early stopping

### 7ï¸âƒ£ **Inference**

* Defines separate inference encoder, decoder, attention models
* Implements step-by-step token generation

### 8ï¸âƒ£ **Streamlit App**

* Accepts English input
* Segments + cleans text
* Predicts French translation interactively

---

## ğŸ’» Demo

ğŸ‘‰ **Try the live demo:**
[ğŸŒ Streamlit Seq2Seq Translator (English â¡ French)](https://seq2seqtranslationenfrwordslevel-9snqxcwdzqz39iw3u63aud.streamlit.app/)


---

## ğŸ–¼ï¸ Images

### ğŸ“Œ App Run

![APP](run_image.png)

### ğŸ“Œ Training Model (Expanded Nested Layers)

![Training Model Nested](training_model_show_nested.png)

---

## âš™ï¸ How to Run Locally

1ï¸âƒ£ **Train model**

```python
# Run provided notebook code
```

2ï¸âƒ£ **Save model/tokenizers**

```python
# Already done in notebook using pickle and model.save()
```

3ï¸âƒ£ **Run Streamlit app**

```bash
streamlit run app.py
```

---

## ğŸ“ˆ Outputs

* Saved models: `model_all.keras`, `model_encoder.keras`, `model_decoder.keras`, `model_attention.keras`
* Tokenizers: `x_tokenizer.pkl`, `y_tokenizer.pkl`
* Token JSONs: `x_tokenizer_tokens_allowed.json`, `y_tokenizer_tokens_allowed.json`
* Visualizations: model architecture PNGs, loss/accuracy plots

---

## ğŸ“ Notes

âš  The inference could be further improved with beam search or other decoding strategies for better translation quality.

---
